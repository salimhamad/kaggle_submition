{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":106809,"databundleVersionId":13056355,"sourceType":"competition"}],"dockerImageVersionId":31236,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import h5py\nimport torch\nimport os\nimport numpy as np\nimport pandas as pd\nfrom pathlib import Path\nfrom tqdm.auto import tqdm\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader, random_split\nfrom torch.nn.utils.rnn import pad_sequence\nfrom torch.cuda.amp import GradScaler, autocast\n\n# --- 1. ڕێکخستنی گشتی ---\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nBASE_PATH = '/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final'\nCHARS = ['BLANK'] + list(\" abcdefghijklmnopqrstuvwxyz' \")\nCHAR_MAP = {c: i for i, c in enumerate(CHARS)}\n\n# --- 2. پۆلێنکردنی داتا بە شێوەی باچ (Batching) ---\nclass NeuralSignalDataset(Dataset):\n    def __init__(self, file_paths):\n        self.samples = []\n        for path in tqdm(file_paths, desc=\"Loading Data\"):\n            if not os.path.exists(path): continue\n            with h5py.File(path, 'r') as hf:\n                for key in hf.keys():\n                    try:\n                        f = hf[key]['input_features'][()]\n                        # نۆرماڵایزکردنی سیگناڵ (گرنگە بۆ ئەوەی لۆسەکە دانەبەزێت)\n                        f = (f - np.mean(f)) / (np.std(f) + 1e-6)\n                        \n                        text = \"\"\n                        for l_key in ['transcription', 'sentence']:\n                            if l_key in hf[key]:\n                                val = hf[key][l_key][()]\n                                text = val.decode('utf-8').lower() if isinstance(val, bytes) else str(val).lower()\n                                break\n                        \n                        if text:\n                            target = [CHAR_MAP[c] for c in text if c in CHAR_MAP]\n                            if len(target) > 0:\n                                self.samples.append((f, target))\n                    except: continue\n\n    def __len__(self): return len(self.samples)\n    def __getitem__(self, idx):\n        return torch.tensor(self.samples[idx][0]).float(), torch.tensor(self.samples[idx][1]).long()\n\n# فەنکشنی ڕێکخستنی درێژی داتاکان (Padding)\ndef collate_fn(batch):\n    inputs, targets = zip(*batch)\n    input_lens = torch.tensor([len(x) for x in inputs])\n    target_lens = torch.tensor([len(y) for y in targets])\n    inputs_padded = pad_sequence(inputs, batch_first=True)\n    targets_padded = pad_sequence(targets, batch_first=True, padding_value=0)\n    return inputs_padded, targets_padded, input_lens, target_lens\n\n# --- 3. مۆدێلی باشترکراو (زیادکردنی Positional Encoding) ---\nclass NeuralTransformerModel(nn.Module):\n    def __init__(self, input_dim=512, hidden_dim=256, nhead=8, num_layers=6):\n        super().__init__()\n        self.feature_projection = nn.Linear(input_dim, hidden_dim)\n        # مۆدێلەکە فێردەکات کام سیگناڵ پێش کامە هاتووە\n        self.pos_embedding = nn.Parameter(torch.randn(1, 3000, hidden_dim)) \n        \n        encoder_layers = nn.TransformerEncoderLayer(\n            d_model=hidden_dim, nhead=nhead, dim_feedforward=hidden_dim*4, \n            dropout=0.2, batch_first=True\n        )\n        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, num_layers=num_layers)\n        self.classifier = nn.Linear(hidden_dim, len(CHARS))\n\n    def forward(self, x):\n        x = self.feature_projection(x) + self.pos_embedding[:, :x.size(1), :]\n        x = self.transformer_encoder(x)\n        return self.classifier(x).log_softmax(2)\n\n# --- 4. پرۆسەی ڕاهێنان (بە باچ و ڤالیدەیشن) ---\ndef execute_training_pipeline():\n    train_files = [str(p) for p in Path(BASE_PATH).rglob('data_train.hdf5')]\n    dataset = NeuralSignalDataset(train_files)\n    \n    # دابەشکردن بۆ Train و Validation بۆ ئەوەی بزانیت فێردەبێت یان نا\n    train_size = int(0.9 * len(dataset))\n    train_ds, val_ds = random_split(dataset, [train_size, len(dataset)-train_size])\n    \n    train_loader = DataLoader(train_ds, batch_size=16, shuffle=True, collate_fn=collate_fn)\n    val_loader = DataLoader(val_ds, batch_size=16, shuffle=False, collate_fn=collate_fn)\n    \n    model = NeuralTransformerModel().to(DEVICE)\n    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=0.05)\n    criterion = nn.CTCLoss(blank=0, zero_infinity=True)\n    \n    # بەکارهێنانی FP16 بۆ خێراکردن و جێگیری\n    scaler = GradScaler()\n    epochs = 30 # ئایپۆکی کەمتر بەڵام کاریگەرتر\n    scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=3e-4, \n                                                    steps_per_epoch=len(train_loader), epochs=epochs)\n\n    for epoch in range(epochs):\n        model.train()\n        total_loss = 0\n        for batch in train_loader:\n            inputs, targets, in_lens, tar_lens = [b.to(DEVICE) if isinstance(b, torch.Tensor) else b for b in batch]\n            optimizer.zero_grad()\n            \n            with autocast():\n                output = model(inputs).permute(1, 0, 2) # CTC loss پێویستی بە (T, N, C) هەیە\n                loss = criterion(output, targets, in_lens, tar_lens)\n            \n            scaler.scale(loss).backward()\n            scaler.unscale_(optimizer)\n            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0) # ڕێگری لە تەقینی لۆس\n            scaler.step(optimizer)\n            scaler.update()\n            scheduler.step()\n            total_loss += loss.item()\n            \n        print(f\"Epoch {epoch+1}/{epochs} - Train Loss: {total_loss/len(train_loader):.4f}\")\n\n    return model\n\n# --- 5. دروستکردنی سەبمیشن ---\ndef generate_submission(model):\n    model.eval()\n    predictions = []\n    test_files = sorted(list(Path(BASE_PATH).rglob(\"data_test.hdf5\")))\n    with torch.no_grad():\n        for f_path in tqdm(test_files):\n            with h5py.File(f_path, \"r\") as hf:\n                keys = sorted(hf.keys(), key=lambda k: int(k.split('_')[1]) if '_' in k else 0)\n                for key in keys:\n                    x = torch.from_numpy(hf[key][\"input_features\"][()]).float().unsqueeze(0).to(DEVICE)\n                    x = (x - x.mean()) / (x.std() + 1e-6)\n                    logits = model(x)\n                    # لێرەدا پیتەکان کۆدەکەینەوە\n                    best_path = torch.argmax(logits[0], dim=-1).unique_consecutive()\n                    decoded = \"\".join([CHARS[i] for i in best_path if i != 0]).strip()\n                    predictions.append(decoded if decoded else \"silence\")\n                    \n    pd.DataFrame({\"id\": range(len(predictions)), \"text\": predictions}).to_csv(\"submission.csv\", index=False)\n    print(\"Submission saved successfully!\")\n\nif __name__ == \"__main__\":\n    final_model = execute_training_pipeline()\n    generate_submission(final_model)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-31T01:00:58.014659Z","iopub.execute_input":"2025-12-31T01:00:58.015011Z","execution_failed":"2025-12-31T01:04:59.239Z"}},"outputs":[],"execution_count":null}]}